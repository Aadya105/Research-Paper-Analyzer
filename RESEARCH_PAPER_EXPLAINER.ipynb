{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGcRj10Nfui0"
   },
   "source": [
    "🔹 STEP 1: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community langchain-core faiss-cpu PyMuPDF\n",
    "!pip install -q langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPUb7W1cf1Xq"
   },
   "source": [
    "🔹 STEP 2: Setup GROQ API Key\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Set your GROQ API key (replace with your actual key)\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4OUr8KOgVAe"
   },
   "source": [
    "🔹 STEP 3: Upload PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ✅ Upload PDF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      3\u001b[39m uploaded = files.upload()\n\u001b[32m      4\u001b[39m pdf_path = \u001b[38;5;28mlist\u001b[39m(uploaded.keys())[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# ✅ Upload PDF\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "pdf_path = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29Mcgl9fglz9"
   },
   "source": [
    "🔹 STEP 4: Load & Split PDF into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 121\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06sZNr0dg5EG"
   },
   "source": [
    "🔹 STEP 5: Create Vector Store (FAISS) Using Gemini Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-6-2898519074.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a611720f29a54dd6856fbc04e01e779a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c3952819d34a588a6a356d526bfb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a44adac140403d8f767438dfc1b098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10474c513a524a1cb8a06a3a9d2c66a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ad8d851adc4f0bad3c1baae2c7dc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c017721395734b64bef4b92f8bd90548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48587e7acc4d49e789a697f733bd5fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d8a64a0bdd459ab9f7c303762b8a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701c7730aa59491a8bc7ae7cd0f46865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d179ad7c094879a412e01d16d834e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7472edf3bb9743e88d57628118c53c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(chunks, embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHKpeFiyhFoS"
   },
   "source": [
    "🔹 STEP 6: Create RAG Chain with GROQ LLM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Load LLM & build RAG chain\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"]\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYMDUPKshYUF"
   },
   "source": [
    "🔹 STEP 7: Ask for Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-8-912533424.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Blog Explainer:\n",
      "\n",
      "Based on the provided context, here's an explanation of the problem, methodology, and key takeaways:\n",
      "\n",
      "**Problem:**\n",
      "The problem revolves around morphing attacks, which are a threat to border crossing and ID management scenarios. Morphing attacks involve creating a fake identity document (e.g., passport) by morphing the face of an individual into another person's face. The goal of a morphing attack is to deceive human observers, particularly ID experts and border guards, into believing that the individual presenting the document is the genuine owner.\n",
      "\n",
      "**Methodology:**\n",
      "To address this problem, researchers are developing methods to detect morphed faces. The methodology involves submitting these methods to ongoing benchmarks, such as the SOTAMD benchmark at the University of Bologna or the U.S. NIST-FRVT-MORPH benchmark. These benchmarks use a sequestered dataset to evaluate the performance of the submitted methods. The evaluation is typically done by fixing the Attack Presentation Classification Error Rate (APCER) at certain values (e.g., 1%, 5%, or 10%) and comparing the performance of different methods.\n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "1. **Morphing attacks are a significant threat**: Morphing attacks can deceive human observers, including ID experts and border guards, which highlights the need for effective detection methods.\n",
      "2. **Benchmarks are essential for evaluation**: The use of benchmarks, such as SOTAMD and NIST-FRVT-MORPH, provides a standardized framework for evaluating the performance of morphed face detection methods.\n",
      "3. **Performance comparison is crucial**: Comparing the performance of different methods, such as MAD Algorithm 3, at fixed APCER values (e.g., 5% or 10%) helps identify the most effective methods for detecting morphed faces.\n",
      "4. **Research is ongoing**: The context suggests that researchers, such as Kiran Raja, Raghavendra Ramachandra, and Ms. Venkatesh, are actively working on developing and evaluating methods for morphed face detection, indicating that this is an ongoing area of research.\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain the problem, methodology, and key takeaways\"\n",
    "response = qa_chain.run(query)\n",
    "\n",
    "print(\"📝 Blog Explainer:\\n\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
